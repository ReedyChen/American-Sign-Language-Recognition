{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKANtHpEZIh8"
      },
      "source": [
        "# Computer Vision Final Project \n",
        "### Author: Yiwei Chen (yc3289),  Daming Liu (dl4430)\n",
        "### Introduction: \n",
        "This is the project which took the dataset of ASLLVD (http://vlm1.uta.edu/~athitsos/asl_lexicon/), which is a integrated dataset for sign languages. This project pick frames representing sign languages of each video as input, and recognize the top choices of sign language of each video segment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lmf078nxavCI",
        "outputId": "606c85e4-ffb5-4e28-d139-380993fc9029"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v0dxl8pZlMq",
        "outputId": "a257add4-19c5-4847-d5a2-2208ab875d65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.5.4.60-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 60.3 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n",
            "Installing collected packages: opencv-python\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed opencv-python-4.5.4.60\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.8.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.7 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (21.2.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.1.2.30)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (0.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.2.2)\n",
            "Requirement already satisfied: protobuf>=3.11.4 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.11.4->mediapipe) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Installing collected packages: mediapipe\n",
            "Successfully installed mediapipe-0.8.9.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -U opencv-python\n",
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJKSr53eZfJx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import csv\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import mediapipe as mp\n",
        "import collections\n",
        "import torch\n",
        "import math\n",
        "from torch import linalg as LA\n",
        "from os import walk\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import *\n",
        "import h5py\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ut9wEcE-RK1"
      },
      "source": [
        "## Parse the annotation file for video from each directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmWph-hoJyW3"
      },
      "outputs": [],
      "source": [
        "def parse(filepath):\n",
        "  annotation = collections.defaultdict(str)\n",
        "  with open(filepath, newline='') as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    for row in reader:\n",
        "      \n",
        "      sessionAndScene = row['MOV']\n",
        "      label = row['Sign gloss']\n",
        "      startFrame = int(row['Gloss start'])\n",
        "      endFrame = int(row['Gloss end'])\n",
        "      totalFrames = endFrame-startFrame\n",
        "      \n",
        "      for frame in range(startFrame, endFrame+1):\n",
        "        position = float(frame - startFrame)/totalFrames\n",
        "        annotation[(sessionAndScene, frame)] = label\n",
        "  return annotation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK0_sgpD_Iws"
      },
      "source": [
        "## Initalize dictionaries for storing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc34Hpi4MZe-"
      },
      "outputs": [],
      "source": [
        "data = collections.defaultdict(list)\n",
        "testData = collections.defaultdict(list)\n",
        "\n",
        "labels = collections.defaultdict(str)\n",
        "ID = 0 # global ID\n",
        "labelsIndex = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPBJtOFO_UPs"
      },
      "source": [
        "## Read and pick the selected frames from each video "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQjiEyTXYxUG"
      },
      "outputs": [],
      "source": [
        "def readVideo(filepath, annotation, test=False):\n",
        "  global ID, data, labels\n",
        "  videoName = (filepath.split('/')[-1]).split('.')[0] \n",
        "  if videoName[-1] != '1':\n",
        "    return\n",
        "  \n",
        "  print(f\"Video Name is {videoName}\")\n",
        "  \n",
        "  # Initalize hands from meidapipe\n",
        "  mpHands = mp.solutions.hands\n",
        "  hands = mpHands.Hands()\n",
        "  mpDraw = mp.solutions.drawing_utils\n",
        "\n",
        "  vid = cv2.VideoCapture(filepath)\n",
        "\n",
        "  # The total frames of this video\n",
        "  frames_total = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  print (f\"Total frames: {frames_total}\")\n",
        "\n",
        "  for frame in range(frames_total):      \n",
        "      ret, img = vid.read()\n",
        "      try:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "      # pick the label of this frame from the annotation file\n",
        "      label = annotation[(videoName, frame)]\n",
        "      if label: \n",
        "        results = hands.process(img)\n",
        "        if results.multi_hand_landmarks:\n",
        "\n",
        "          # left hand = 0; right hand = 1\n",
        "          hand = 0\n",
        "          datasetLeft = []\n",
        "          datasetRight = []\n",
        "          \n",
        "          # a handLms presenting 21 joints of a recognized hand, each joint has x,y,z coordinates\n",
        "          # https://google.github.io/mediapipe/solutions/hands.html\n",
        "          for handLms in results.multi_hand_landmarks:\n",
        "            handLandMarks = []\n",
        "            for id, lm in enumerate(handLms.landmark):\n",
        "              if id == 0:\n",
        "                # record the wrist position \n",
        "                x,y,z = lm.x, lm.y, lm.z \n",
        "              handLandMarks.append([lm.x-x, lm.y-y, lm.z-z]) # Normalize each joint to relative position to the wrist\n",
        "            \n",
        "            if hand == 0:\n",
        "              datasetLeft.append(handLandMarks)\n",
        "            elif hand == 1:\n",
        "              datasetRight.append(handLandMarks)\n",
        "            hand += 1\n",
        "\n",
        "          # if this is a one hand gesture, fill the right hand with zeros\n",
        "          if hand == 1:\n",
        "            datasetRight.append(np.zeros((21, 3)))\n",
        "\n",
        "          if not test:\n",
        "            data[ID] = np.array([datasetLeft, datasetRight])\n",
        "          else:\n",
        "            testData[ID] = np.array([datasetLeft, datasetRight])\n",
        "          labels[ID] = label\n",
        "          ID += 1\n",
        "\n",
        "  # Release resources and Destroy all the windows\n",
        "  vid.release() \n",
        "  cv2.destroyAllWindows() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuKVoAMl1Cap"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9ZRgqfG6cg1",
        "outputId": "f1c7ebd4-c865-4c21-8015-686ed9c36f34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dana/\n",
            "Video Name is scene6-camera1\n",
            "Total frames: 3536\n",
            "Video Name is scene7-camera1\n",
            "Total frames: 3400\n",
            "Liz/\n",
            "Video Name is scene1-camera1\n",
            "Total frames: 2036\n",
            "Video Name is scene10-camera1\n",
            "Total frames: 3368\n",
            "Video Name is scene2-camera1\n",
            "Total frames: 3604\n",
            "Video Name is scene3-camera1\n",
            "Total frames: 3604\n",
            "Video Name is scene4-camera1\n",
            "Total frames: 3604\n",
            "Video Name is scene5-camera1\n",
            "Total frames: 2460\n",
            "Video Name is scene6-camera1\n",
            "Total frames: 3536\n",
            "Video Name is scene7-camera1\n",
            "Total frames: 3400\n",
            "Video Name is scene8-camera1\n",
            "Total frames: 3276\n",
            "Video Name is scene9-camera1\n",
            "Total frames: 3256\n",
            "Video Name is scene11-camera1\n",
            "Total frames: 1644\n",
            "Video Name is scene12-camera1\n",
            "Total frames: 1768\n",
            "Video Name is scene13-camera1\n",
            "Total frames: 1924\n",
            "Video Name is scene14-camera1\n",
            "Total frames: 1664\n",
            "Video Name is scene15-camera1\n",
            "Total frames: 1704\n",
            "Video Name is scene16-camera1\n",
            "Total frames: 932\n",
            "Video Name is scene17-camera1\n",
            "Total frames: 364\n",
            "Video Name is scene18-camera1\n",
            "Total frames: 2136\n",
            "Video Name is scene19-camera1\n",
            "Total frames: 2120\n",
            "Video Name is scene20-camera1\n",
            "Total frames: 3848\n",
            "Video Name is scene21-camera1\n",
            "Total frames: 5169\n",
            "Video Name is scene22-camera1\n",
            "Total frames: 1824\n",
            "Video Name is scene23-camera1\n",
            "Total frames: 1492\n",
            "Video Name is scene24-camera1\n",
            "Total frames: 1652\n",
            "Video Name is scene25-camera1\n",
            "Total frames: 2044\n",
            "Video Name is scene26-camera1\n",
            "Total frames: 2152\n",
            "Video Name is scene27-camera1\n",
            "Total frames: 1832\n",
            "Tyler/\n",
            "Video Name is scene1-camera1\n",
            "Total frames: 2724\n",
            "Video Name is scene10-camera1\n",
            "Total frames: 4564\n",
            "Video Name is scene11-camera1\n",
            "Total frames: 3032\n",
            "Video Name is scene12-camera1\n",
            "Total frames: 6132\n",
            "Video Name is scene13-camera1\n",
            "Total frames: 3188\n",
            "Video Name is scene14-camera1\n",
            "Total frames: 3172\n",
            "Video Name is scene15-camera1\n",
            "Total frames: 4372\n",
            "Video Name is scene16-camera1\n",
            "Total frames: 4760\n",
            "Video Name is scene17-camera1\n",
            "Total frames: 4100\n",
            "Video Name is scene18-camera1\n",
            "Total frames: 4604\n",
            "Video Name is scene2-camera1\n",
            "Total frames: 2504\n",
            "Video Name is scene3-camera1\n",
            "Total frames: 2572\n",
            "Video Name is scene5-camera1\n",
            "Total frames: 356\n",
            "Video Name is scene4-camera1\n",
            "Total frames: 2564\n",
            "Video Name is scene6-camera1\n",
            "Total frames: 8228\n",
            "Video Name is scene7-camera1\n",
            "Total frames: 3664\n",
            "Video Name is scene8-camera1\n",
            "Total frames: 3752\n",
            "Video Name is scene9-camera1\n",
            "Total frames: 4288\n",
            "naomi/\n",
            "Video Name is scene1-camera1\n",
            "Total frames: 2444\n",
            "Video Name is scene10-camera1\n",
            "Total frames: 3440\n",
            "Video Name is scene11-camera1\n",
            "Total frames: 608\n",
            "Video Name is scene12-camera1\n",
            "Total frames: 3024\n",
            "Video Name is scene13-camera1\n",
            "Total frames: 4084\n",
            "Video Name is scene14-camera1\n",
            "Total frames: 3044\n",
            "Video Name is scene15-camera1\n",
            "Total frames: 3784\n",
            "Video Name is scene16-camera1\n",
            "Total frames: 5908\n",
            "Video Name is scene17-camera1\n",
            "Total frames: 3608\n",
            "Video Name is scene18-camera1\n",
            "Total frames: 3948\n",
            "Video Name is scene2-camera1\n",
            "Total frames: 3492\n",
            "Video Name is scene3-camera1\n",
            "Total frames: 3036\n",
            "Video Name is scene4-camera1\n",
            "Total frames: 4688\n",
            "Video Name is scene5-camera1\n",
            "Total frames: 4032\n",
            "Video Name is scene6-camera1\n",
            "Total frames: 3828\n",
            "Video Name is scene7-camera1\n",
            "Total frames: 4772\n",
            "Video Name is scene8-camera1\n",
            "Total frames: 3404\n",
            "Video Name is scene9-camera1\n",
            "Total frames: 3876\n",
            "Lana/\n",
            "Video Name is scene2-camera1\n",
            "Total frames: 3148\n",
            "Video Name is scene3-camera1\n",
            "Total frames: 3148\n"
          ]
        }
      ],
      "source": [
        "# load training data\n",
        "dirs = ['Dana/', 'Liz/', 'Tyler/', 'naomi/']\n",
        "\n",
        "prefix = '/content/drive/MyDrive/cv_project/'\n",
        "for dir in dirs:\n",
        "  print (dir)\n",
        "  dir = prefix + dir\n",
        "  for (dirpath, dirnames, filenames) in walk(dir):\n",
        "    for filename in filenames:\n",
        "      annotation = parse(dir + 'annotation.csv')\n",
        "      if filename.split('.')[-1] == 'avi':\n",
        "        readVideo(dir+filename, annotation) \n",
        "\n",
        "# load testing data\n",
        "dirs = ['Lana/']\n",
        "for dir in dirs:\n",
        "  print (dir)\n",
        "  dir = prefix + dir\n",
        "  for (dirpath, dirnames, filenames) in walk(dir):\n",
        "    for filename in filenames:\n",
        "      annotation = parse(dir + 'annotation.csv')\n",
        "      if filename.split('.')[-1] == 'avi':\n",
        "        readVideo(dir+filename, annotation, True) # testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uq2KYpe4trc",
        "outputId": "34871c16-d5e3-4ce1-a9e7-fb288abf17f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of labels: 162\n",
            "length of train samples: 17786\n",
            "length of test samples: 476\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of labels: {len(set(labels.values()))}\")\n",
        "print(f\"length of train samples: {len(data)}\")\n",
        "print(f\"length of test samples: {len(testData)}\")\n",
        "\n",
        "labelsIndex = list(set(labels.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJDUgqw6cAy9"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "  'Characterizes a dataset for PyTorch'\n",
        "  def __init__(self, list_IDs, labels, data):\n",
        "        'Initialization'\n",
        "        self.labels = labels\n",
        "        self.list_IDs = list_IDs\n",
        "        self.data = data\n",
        "\n",
        "  def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.list_IDs)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        # Select sample\n",
        "        ID = self.list_IDs[index]\n",
        "\n",
        "        # Load data and get label\n",
        "        X = (self.data[ID]).astype(np.float32)\n",
        "        y = float(labelsIndex.index(self.labels[ID]))\n",
        "\n",
        "        return X, y\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfSRUsxpBmDM"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK-xkv8laolt",
        "outputId": "fb2279ac-6f9b-4f26-a04b-24782c715ff7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17786 476\n",
            "Feature batch shape: torch.Size([8, 2, 1, 21, 3])\n",
            "Labels batch shape: tensor([ 74.,  33.,   8., 103., 113., 161.,  83.,  89.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "batch_size = 8\n",
        "\n",
        "# Random shuffle test data and train data\n",
        "l = list(data.items())\n",
        "random.shuffle(l)\n",
        "\n",
        "l_train = dict(l)\n",
        "l = list(testData.items())\n",
        "random.shuffle(l)\n",
        "\n",
        "l_test = dict(l)\n",
        "\n",
        "print(len(l_train), len(l_test))\n",
        "\n",
        "trainDataset = Dataset(list(l_train.keys()), labels, l_train)\n",
        "train_loader = DataLoader(trainDataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "testDataset = Dataset(list(l_test.keys()), labels, l_test)\n",
        "test_loader = DataLoader(testDataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fY1nXFxGapKK",
        "outputId": "23f3d5c0-43eb-453b-85a3-72d1b8b38ff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 162])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# 3D CNN convolutional network\n",
        "# input size is (batch_size, 2, 1, 21, 3)\n",
        "class Net3d(nn.Module):\n",
        "    \n",
        "    # Contructor\n",
        "    def __init__(self):\n",
        "        super(Net3d, self).__init__()\n",
        "\n",
        "        self.conv_layer1 = self._conv_layer_set(2, 64)\n",
        "        self.conv_layer2 = self._conv_layer_set(64, 64)\n",
        "        self.fc1 = nn.Linear(768, 128)\n",
        "        self.fc2 = nn.Linear(128, len(labelsIndex))\n",
        "        self.relu = nn.LeakyReLU()\n",
        "        self.batch=nn.BatchNorm1d(128)\n",
        "        self.drop=nn.Dropout(p=0.15)   \n",
        "    \n",
        "    def _conv_layer_set(self, in_c, out_c):\n",
        "        conv_layer = nn.Sequential(\n",
        "        nn.Conv3d(in_c, out_c, kernel_size=(3, 3, 3), padding=2),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.MaxPool3d((2, 2, 2)),\n",
        "        )\n",
        "        return conv_layer\n",
        "\n",
        "    # Prediction\n",
        "    def forward(self, x):\n",
        "        out = self.conv_layer1(x)\n",
        "        out = self.conv_layer2(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.batch(out)\n",
        "        out = self.drop(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "input = torch.randn(2, 2, 1, 21, 3)\n",
        "\n",
        "model = Net3d()\n",
        "output = model(input)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-OoS76nCIu9"
      },
      "source": [
        "## Train the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkMMU8Y9gxH4",
        "outputId": "5ee5f246-9829-4e16-c768-539655430e62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/17786 (0%)]\tLoss: 5.112056\n",
            "Train Epoch: 1 [800/17786 (4%)]\tLoss: 5.108453\n",
            "Train Epoch: 1 [1600/17786 (9%)]\tLoss: 4.944288\n",
            "Train Epoch: 1 [2400/17786 (13%)]\tLoss: 4.725092\n",
            "Train Epoch: 1 [3200/17786 (18%)]\tLoss: 4.635938\n",
            "Train Epoch: 1 [4000/17786 (22%)]\tLoss: 4.427299\n",
            "Train Epoch: 1 [4800/17786 (27%)]\tLoss: 4.528893\n",
            "Train Epoch: 1 [5600/17786 (31%)]\tLoss: 4.657877\n",
            "Train Epoch: 1 [6400/17786 (36%)]\tLoss: 4.820730\n",
            "Train Epoch: 1 [7200/17786 (40%)]\tLoss: 4.670703\n",
            "Train Epoch: 1 [8000/17786 (45%)]\tLoss: 4.418600\n",
            "Train Epoch: 1 [8800/17786 (49%)]\tLoss: 3.783590\n",
            "Train Epoch: 1 [9600/17786 (54%)]\tLoss: 4.401461\n",
            "Train Epoch: 1 [10400/17786 (58%)]\tLoss: 4.101380\n",
            "Train Epoch: 1 [11200/17786 (63%)]\tLoss: 4.068273\n",
            "Train Epoch: 1 [12000/17786 (67%)]\tLoss: 4.031943\n",
            "Train Epoch: 1 [12800/17786 (72%)]\tLoss: 3.772090\n",
            "Train Epoch: 1 [13600/17786 (76%)]\tLoss: 4.005735\n",
            "Train Epoch: 1 [14400/17786 (81%)]\tLoss: 3.798682\n",
            "Train Epoch: 1 [15200/17786 (85%)]\tLoss: 3.708657\n",
            "Train Epoch: 1 [16000/17786 (90%)]\tLoss: 3.429667\n",
            "Train Epoch: 1 [16800/17786 (94%)]\tLoss: 3.046192\n",
            "Train Epoch: 1 [17600/17786 (99%)]\tLoss: 3.593843\n",
            "Train Epoch: 2 [0/17786 (0%)]\tLoss: 3.630482\n",
            "Train Epoch: 2 [800/17786 (4%)]\tLoss: 3.895703\n",
            "Train Epoch: 2 [1600/17786 (9%)]\tLoss: 3.736219\n",
            "Train Epoch: 2 [2400/17786 (13%)]\tLoss: 3.012052\n",
            "Train Epoch: 2 [3200/17786 (18%)]\tLoss: 2.900940\n",
            "Train Epoch: 2 [4000/17786 (22%)]\tLoss: 3.409122\n",
            "Train Epoch: 2 [4800/17786 (27%)]\tLoss: 3.194922\n",
            "Train Epoch: 2 [5600/17786 (31%)]\tLoss: 3.016621\n",
            "Train Epoch: 2 [6400/17786 (36%)]\tLoss: 3.604475\n",
            "Train Epoch: 2 [7200/17786 (40%)]\tLoss: 2.864464\n",
            "Train Epoch: 2 [8000/17786 (45%)]\tLoss: 3.589344\n",
            "Train Epoch: 2 [8800/17786 (49%)]\tLoss: 2.963399\n",
            "Train Epoch: 2 [9600/17786 (54%)]\tLoss: 3.782468\n",
            "Train Epoch: 2 [10400/17786 (58%)]\tLoss: 2.807521\n",
            "Train Epoch: 2 [11200/17786 (63%)]\tLoss: 2.686932\n",
            "Train Epoch: 2 [12000/17786 (67%)]\tLoss: 2.728659\n",
            "Train Epoch: 2 [12800/17786 (72%)]\tLoss: 3.201756\n",
            "Train Epoch: 2 [13600/17786 (76%)]\tLoss: 3.762696\n",
            "Train Epoch: 2 [14400/17786 (81%)]\tLoss: 2.410203\n",
            "Train Epoch: 2 [15200/17786 (85%)]\tLoss: 3.243141\n",
            "Train Epoch: 2 [16000/17786 (90%)]\tLoss: 2.184493\n",
            "Train Epoch: 2 [16800/17786 (94%)]\tLoss: 2.630107\n",
            "Train Epoch: 2 [17600/17786 (99%)]\tLoss: 2.344044\n",
            "Train Epoch: 3 [0/17786 (0%)]\tLoss: 2.552167\n",
            "Train Epoch: 3 [800/17786 (4%)]\tLoss: 2.831602\n",
            "Train Epoch: 3 [1600/17786 (9%)]\tLoss: 2.217386\n",
            "Train Epoch: 3 [2400/17786 (13%)]\tLoss: 2.329942\n",
            "Train Epoch: 3 [3200/17786 (18%)]\tLoss: 2.631755\n",
            "Train Epoch: 3 [4000/17786 (22%)]\tLoss: 2.099337\n",
            "Train Epoch: 3 [4800/17786 (27%)]\tLoss: 2.320635\n",
            "Train Epoch: 3 [5600/17786 (31%)]\tLoss: 2.148068\n",
            "Train Epoch: 3 [6400/17786 (36%)]\tLoss: 1.953941\n",
            "Train Epoch: 3 [7200/17786 (40%)]\tLoss: 1.879875\n",
            "Train Epoch: 3 [8000/17786 (45%)]\tLoss: 3.189230\n",
            "Train Epoch: 3 [8800/17786 (49%)]\tLoss: 2.274913\n",
            "Train Epoch: 3 [9600/17786 (54%)]\tLoss: 2.535609\n",
            "Train Epoch: 3 [10400/17786 (58%)]\tLoss: 2.273877\n",
            "Train Epoch: 3 [11200/17786 (63%)]\tLoss: 3.039281\n",
            "Train Epoch: 3 [12000/17786 (67%)]\tLoss: 2.790664\n",
            "Train Epoch: 3 [12800/17786 (72%)]\tLoss: 2.094684\n",
            "Train Epoch: 3 [13600/17786 (76%)]\tLoss: 1.873091\n",
            "Train Epoch: 3 [14400/17786 (81%)]\tLoss: 1.924515\n",
            "Train Epoch: 3 [15200/17786 (85%)]\tLoss: 2.680311\n",
            "Train Epoch: 3 [16000/17786 (90%)]\tLoss: 2.495636\n",
            "Train Epoch: 3 [16800/17786 (94%)]\tLoss: 1.713006\n",
            "Train Epoch: 3 [17600/17786 (99%)]\tLoss: 2.805385\n",
            "Train Epoch: 4 [0/17786 (0%)]\tLoss: 2.109823\n",
            "Train Epoch: 4 [800/17786 (4%)]\tLoss: 2.344348\n",
            "Train Epoch: 4 [1600/17786 (9%)]\tLoss: 1.766679\n",
            "Train Epoch: 4 [2400/17786 (13%)]\tLoss: 1.880432\n",
            "Train Epoch: 4 [3200/17786 (18%)]\tLoss: 1.976546\n",
            "Train Epoch: 4 [4000/17786 (22%)]\tLoss: 1.267932\n",
            "Train Epoch: 4 [4800/17786 (27%)]\tLoss: 1.872060\n",
            "Train Epoch: 4 [5600/17786 (31%)]\tLoss: 2.099047\n",
            "Train Epoch: 4 [6400/17786 (36%)]\tLoss: 1.497749\n",
            "Train Epoch: 4 [7200/17786 (40%)]\tLoss: 1.065148\n",
            "Train Epoch: 4 [8000/17786 (45%)]\tLoss: 2.702900\n",
            "Train Epoch: 4 [8800/17786 (49%)]\tLoss: 1.752409\n",
            "Train Epoch: 4 [9600/17786 (54%)]\tLoss: 1.378390\n",
            "Train Epoch: 4 [10400/17786 (58%)]\tLoss: 1.145894\n",
            "Train Epoch: 4 [11200/17786 (63%)]\tLoss: 1.153834\n",
            "Train Epoch: 4 [12000/17786 (67%)]\tLoss: 0.994843\n",
            "Train Epoch: 4 [12800/17786 (72%)]\tLoss: 2.335162\n",
            "Train Epoch: 4 [13600/17786 (76%)]\tLoss: 1.270184\n",
            "Train Epoch: 4 [14400/17786 (81%)]\tLoss: 1.588378\n",
            "Train Epoch: 4 [15200/17786 (85%)]\tLoss: 1.746901\n",
            "Train Epoch: 4 [16000/17786 (90%)]\tLoss: 2.155375\n",
            "Train Epoch: 4 [16800/17786 (94%)]\tLoss: 1.903737\n",
            "Train Epoch: 4 [17600/17786 (99%)]\tLoss: 1.536522\n",
            "Train Epoch: 5 [0/17786 (0%)]\tLoss: 1.558906\n",
            "Train Epoch: 5 [800/17786 (4%)]\tLoss: 0.878278\n",
            "Train Epoch: 5 [1600/17786 (9%)]\tLoss: 1.403439\n",
            "Train Epoch: 5 [2400/17786 (13%)]\tLoss: 1.297644\n",
            "Train Epoch: 5 [3200/17786 (18%)]\tLoss: 0.865922\n",
            "Train Epoch: 5 [4000/17786 (22%)]\tLoss: 3.751654\n",
            "Train Epoch: 5 [4800/17786 (27%)]\tLoss: 1.127564\n",
            "Train Epoch: 5 [5600/17786 (31%)]\tLoss: 3.477433\n",
            "Train Epoch: 5 [6400/17786 (36%)]\tLoss: 0.834800\n",
            "Train Epoch: 5 [7200/17786 (40%)]\tLoss: 0.990157\n",
            "Train Epoch: 5 [8000/17786 (45%)]\tLoss: 2.051578\n",
            "Train Epoch: 5 [8800/17786 (49%)]\tLoss: 0.689695\n",
            "Train Epoch: 5 [9600/17786 (54%)]\tLoss: 1.692257\n",
            "Train Epoch: 5 [10400/17786 (58%)]\tLoss: 1.367474\n",
            "Train Epoch: 5 [11200/17786 (63%)]\tLoss: 1.830509\n",
            "Train Epoch: 5 [12000/17786 (67%)]\tLoss: 1.279280\n",
            "Train Epoch: 5 [12800/17786 (72%)]\tLoss: 1.976404\n",
            "Train Epoch: 5 [13600/17786 (76%)]\tLoss: 1.612267\n",
            "Train Epoch: 5 [14400/17786 (81%)]\tLoss: 1.232653\n",
            "Train Epoch: 5 [15200/17786 (85%)]\tLoss: 1.357739\n",
            "Train Epoch: 5 [16000/17786 (90%)]\tLoss: 1.609248\n",
            "Train Epoch: 5 [16800/17786 (94%)]\tLoss: 1.087493\n",
            "Train Epoch: 5 [17600/17786 (99%)]\tLoss: 1.295968\n",
            "Train Epoch: 6 [0/17786 (0%)]\tLoss: 1.756067\n",
            "Train Epoch: 6 [800/17786 (4%)]\tLoss: 1.130339\n",
            "Train Epoch: 6 [1600/17786 (9%)]\tLoss: 1.481060\n",
            "Train Epoch: 6 [2400/17786 (13%)]\tLoss: 2.405674\n",
            "Train Epoch: 6 [3200/17786 (18%)]\tLoss: 0.775299\n",
            "Train Epoch: 6 [4000/17786 (22%)]\tLoss: 1.438655\n",
            "Train Epoch: 6 [4800/17786 (27%)]\tLoss: 1.276673\n",
            "Train Epoch: 6 [5600/17786 (31%)]\tLoss: 0.702872\n",
            "Train Epoch: 6 [6400/17786 (36%)]\tLoss: 0.824029\n",
            "Train Epoch: 6 [7200/17786 (40%)]\tLoss: 1.139338\n",
            "Train Epoch: 6 [8000/17786 (45%)]\tLoss: 0.945015\n",
            "Train Epoch: 6 [8800/17786 (49%)]\tLoss: 0.825259\n",
            "Train Epoch: 6 [9600/17786 (54%)]\tLoss: 1.557849\n",
            "Train Epoch: 6 [10400/17786 (58%)]\tLoss: 1.267973\n",
            "Train Epoch: 6 [11200/17786 (63%)]\tLoss: 1.360973\n",
            "Train Epoch: 6 [12000/17786 (67%)]\tLoss: 1.411151\n",
            "Train Epoch: 6 [12800/17786 (72%)]\tLoss: 1.580472\n",
            "Train Epoch: 6 [13600/17786 (76%)]\tLoss: 1.062227\n",
            "Train Epoch: 6 [14400/17786 (81%)]\tLoss: 1.867403\n",
            "Train Epoch: 6 [15200/17786 (85%)]\tLoss: 1.208932\n",
            "Train Epoch: 6 [16000/17786 (90%)]\tLoss: 1.127634\n",
            "Train Epoch: 6 [16800/17786 (94%)]\tLoss: 1.282283\n",
            "Train Epoch: 6 [17600/17786 (99%)]\tLoss: 2.275920\n",
            "Train Epoch: 7 [0/17786 (0%)]\tLoss: 1.428297\n",
            "Train Epoch: 7 [800/17786 (4%)]\tLoss: 1.058443\n",
            "Train Epoch: 7 [1600/17786 (9%)]\tLoss: 1.304834\n",
            "Train Epoch: 7 [2400/17786 (13%)]\tLoss: 1.368648\n",
            "Train Epoch: 7 [3200/17786 (18%)]\tLoss: 1.208269\n",
            "Train Epoch: 7 [4000/17786 (22%)]\tLoss: 0.405304\n",
            "Train Epoch: 7 [4800/17786 (27%)]\tLoss: 0.541037\n",
            "Train Epoch: 7 [5600/17786 (31%)]\tLoss: 1.704089\n",
            "Train Epoch: 7 [6400/17786 (36%)]\tLoss: 1.214180\n",
            "Train Epoch: 7 [7200/17786 (40%)]\tLoss: 1.914504\n",
            "Train Epoch: 7 [8000/17786 (45%)]\tLoss: 1.359730\n",
            "Train Epoch: 7 [8800/17786 (49%)]\tLoss: 1.360406\n",
            "Train Epoch: 7 [9600/17786 (54%)]\tLoss: 1.320006\n",
            "Train Epoch: 7 [10400/17786 (58%)]\tLoss: 0.980485\n",
            "Train Epoch: 7 [11200/17786 (63%)]\tLoss: 1.231995\n",
            "Train Epoch: 7 [12000/17786 (67%)]\tLoss: 1.435440\n",
            "Train Epoch: 7 [12800/17786 (72%)]\tLoss: 1.923208\n",
            "Train Epoch: 7 [13600/17786 (76%)]\tLoss: 0.990721\n",
            "Train Epoch: 7 [14400/17786 (81%)]\tLoss: 0.837054\n",
            "Train Epoch: 7 [15200/17786 (85%)]\tLoss: 0.846834\n",
            "Train Epoch: 7 [16000/17786 (90%)]\tLoss: 1.399145\n",
            "Train Epoch: 7 [16800/17786 (94%)]\tLoss: 0.849846\n",
            "Train Epoch: 7 [17600/17786 (99%)]\tLoss: 1.048019\n",
            "Train Epoch: 8 [0/17786 (0%)]\tLoss: 1.498856\n",
            "Train Epoch: 8 [800/17786 (4%)]\tLoss: 0.484383\n",
            "Train Epoch: 8 [1600/17786 (9%)]\tLoss: 2.231992\n",
            "Train Epoch: 8 [2400/17786 (13%)]\tLoss: 1.626160\n",
            "Train Epoch: 8 [3200/17786 (18%)]\tLoss: 1.261197\n",
            "Train Epoch: 8 [4000/17786 (22%)]\tLoss: 0.500082\n",
            "Train Epoch: 8 [4800/17786 (27%)]\tLoss: 0.775882\n",
            "Train Epoch: 8 [5600/17786 (31%)]\tLoss: 1.053874\n",
            "Train Epoch: 8 [6400/17786 (36%)]\tLoss: 0.994983\n",
            "Train Epoch: 8 [7200/17786 (40%)]\tLoss: 1.595185\n",
            "Train Epoch: 8 [8000/17786 (45%)]\tLoss: 1.866504\n",
            "Train Epoch: 8 [8800/17786 (49%)]\tLoss: 1.299921\n",
            "Train Epoch: 8 [9600/17786 (54%)]\tLoss: 1.017636\n",
            "Train Epoch: 8 [10400/17786 (58%)]\tLoss: 1.794717\n",
            "Train Epoch: 8 [11200/17786 (63%)]\tLoss: 1.087908\n",
            "Train Epoch: 8 [12000/17786 (67%)]\tLoss: 0.444619\n",
            "Train Epoch: 8 [12800/17786 (72%)]\tLoss: 1.275719\n",
            "Train Epoch: 8 [13600/17786 (76%)]\tLoss: 1.194584\n",
            "Train Epoch: 8 [14400/17786 (81%)]\tLoss: 1.346955\n",
            "Train Epoch: 8 [15200/17786 (85%)]\tLoss: 0.607439\n",
            "Train Epoch: 8 [16000/17786 (90%)]\tLoss: 0.981088\n",
            "Train Epoch: 8 [16800/17786 (94%)]\tLoss: 1.389100\n",
            "Train Epoch: 8 [17600/17786 (99%)]\tLoss: 0.728847\n",
            "Train Epoch: 9 [0/17786 (0%)]\tLoss: 1.274328\n",
            "Train Epoch: 9 [800/17786 (4%)]\tLoss: 0.270945\n",
            "Train Epoch: 9 [1600/17786 (9%)]\tLoss: 0.671008\n",
            "Train Epoch: 9 [2400/17786 (13%)]\tLoss: 0.856775\n",
            "Train Epoch: 9 [3200/17786 (18%)]\tLoss: 1.008790\n",
            "Train Epoch: 9 [4000/17786 (22%)]\tLoss: 1.314729\n",
            "Train Epoch: 9 [4800/17786 (27%)]\tLoss: 1.070386\n",
            "Train Epoch: 9 [5600/17786 (31%)]\tLoss: 1.515671\n",
            "Train Epoch: 9 [6400/17786 (36%)]\tLoss: 1.071691\n",
            "Train Epoch: 9 [7200/17786 (40%)]\tLoss: 0.916920\n",
            "Train Epoch: 9 [8000/17786 (45%)]\tLoss: 1.256461\n",
            "Train Epoch: 9 [8800/17786 (49%)]\tLoss: 1.436208\n",
            "Train Epoch: 9 [9600/17786 (54%)]\tLoss: 2.190031\n",
            "Train Epoch: 9 [10400/17786 (58%)]\tLoss: 1.185084\n",
            "Train Epoch: 9 [11200/17786 (63%)]\tLoss: 0.979478\n",
            "Train Epoch: 9 [12000/17786 (67%)]\tLoss: 1.255407\n",
            "Train Epoch: 9 [12800/17786 (72%)]\tLoss: 1.785032\n",
            "Train Epoch: 9 [13600/17786 (76%)]\tLoss: 0.803749\n",
            "Train Epoch: 9 [14400/17786 (81%)]\tLoss: 0.979881\n",
            "Train Epoch: 9 [15200/17786 (85%)]\tLoss: 0.682445\n",
            "Train Epoch: 9 [16000/17786 (90%)]\tLoss: 2.822421\n",
            "Train Epoch: 9 [16800/17786 (94%)]\tLoss: 0.948158\n",
            "Train Epoch: 9 [17600/17786 (99%)]\tLoss: 0.808180\n",
            "Train Epoch: 10 [0/17786 (0%)]\tLoss: 0.683087\n",
            "Train Epoch: 10 [800/17786 (4%)]\tLoss: 0.852897\n",
            "Train Epoch: 10 [1600/17786 (9%)]\tLoss: 0.976619\n",
            "Train Epoch: 10 [2400/17786 (13%)]\tLoss: 0.711052\n",
            "Train Epoch: 10 [3200/17786 (18%)]\tLoss: 0.564799\n",
            "Train Epoch: 10 [4000/17786 (22%)]\tLoss: 0.737860\n",
            "Train Epoch: 10 [4800/17786 (27%)]\tLoss: 1.445436\n",
            "Train Epoch: 10 [5600/17786 (31%)]\tLoss: 0.920571\n",
            "Train Epoch: 10 [6400/17786 (36%)]\tLoss: 0.642905\n",
            "Train Epoch: 10 [7200/17786 (40%)]\tLoss: 0.727339\n",
            "Train Epoch: 10 [8000/17786 (45%)]\tLoss: 0.932028\n",
            "Train Epoch: 10 [8800/17786 (49%)]\tLoss: 1.484959\n",
            "Train Epoch: 10 [9600/17786 (54%)]\tLoss: 2.276772\n",
            "Train Epoch: 10 [10400/17786 (58%)]\tLoss: 1.776368\n",
            "Train Epoch: 10 [11200/17786 (63%)]\tLoss: 2.525927\n",
            "Train Epoch: 10 [12000/17786 (67%)]\tLoss: 1.081498\n",
            "Train Epoch: 10 [12800/17786 (72%)]\tLoss: 1.260791\n",
            "Train Epoch: 10 [13600/17786 (76%)]\tLoss: 0.395241\n",
            "Train Epoch: 10 [14400/17786 (81%)]\tLoss: 0.718824\n",
            "Train Epoch: 10 [15200/17786 (85%)]\tLoss: 0.811903\n",
            "Train Epoch: 10 [16000/17786 (90%)]\tLoss: 0.537559\n",
            "Train Epoch: 10 [16800/17786 (94%)]\tLoss: 1.299600\n",
            "Train Epoch: 10 [17600/17786 (99%)]\tLoss: 1.279955\n",
            "Train Epoch: 11 [0/17786 (0%)]\tLoss: 1.067690\n",
            "Train Epoch: 11 [800/17786 (4%)]\tLoss: 0.972073\n",
            "Train Epoch: 11 [1600/17786 (9%)]\tLoss: 0.637157\n",
            "Train Epoch: 11 [2400/17786 (13%)]\tLoss: 0.903099\n",
            "Train Epoch: 11 [3200/17786 (18%)]\tLoss: 0.935928\n",
            "Train Epoch: 11 [4000/17786 (22%)]\tLoss: 1.510146\n",
            "Train Epoch: 11 [4800/17786 (27%)]\tLoss: 0.359270\n",
            "Train Epoch: 11 [5600/17786 (31%)]\tLoss: 0.746329\n",
            "Train Epoch: 11 [6400/17786 (36%)]\tLoss: 0.734364\n",
            "Train Epoch: 11 [7200/17786 (40%)]\tLoss: 1.179247\n",
            "Train Epoch: 11 [8000/17786 (45%)]\tLoss: 0.671734\n",
            "Train Epoch: 11 [8800/17786 (49%)]\tLoss: 0.500641\n",
            "Train Epoch: 11 [9600/17786 (54%)]\tLoss: 1.380993\n",
            "Train Epoch: 11 [10400/17786 (58%)]\tLoss: 0.797366\n",
            "Train Epoch: 11 [11200/17786 (63%)]\tLoss: 1.483907\n",
            "Train Epoch: 11 [12000/17786 (67%)]\tLoss: 0.521550\n",
            "Train Epoch: 11 [12800/17786 (72%)]\tLoss: 1.224142\n",
            "Train Epoch: 11 [13600/17786 (76%)]\tLoss: 0.689033\n",
            "Train Epoch: 11 [14400/17786 (81%)]\tLoss: 1.391224\n",
            "Train Epoch: 11 [15200/17786 (85%)]\tLoss: 1.427858\n",
            "Train Epoch: 11 [16000/17786 (90%)]\tLoss: 1.214607\n",
            "Train Epoch: 11 [16800/17786 (94%)]\tLoss: 0.917477\n",
            "Train Epoch: 11 [17600/17786 (99%)]\tLoss: 0.399760\n",
            "Train Epoch: 12 [0/17786 (0%)]\tLoss: 0.813544\n",
            "Train Epoch: 12 [800/17786 (4%)]\tLoss: 1.480769\n",
            "Train Epoch: 12 [1600/17786 (9%)]\tLoss: 0.931260\n",
            "Train Epoch: 12 [2400/17786 (13%)]\tLoss: 0.799054\n",
            "Train Epoch: 12 [3200/17786 (18%)]\tLoss: 0.632026\n",
            "Train Epoch: 12 [4000/17786 (22%)]\tLoss: 0.595065\n",
            "Train Epoch: 12 [4800/17786 (27%)]\tLoss: 1.346637\n",
            "Train Epoch: 12 [5600/17786 (31%)]\tLoss: 1.530449\n",
            "Train Epoch: 12 [6400/17786 (36%)]\tLoss: 0.921824\n",
            "Train Epoch: 12 [7200/17786 (40%)]\tLoss: 0.676587\n",
            "Train Epoch: 12 [8000/17786 (45%)]\tLoss: 1.940762\n",
            "Train Epoch: 12 [8800/17786 (49%)]\tLoss: 0.444467\n",
            "Train Epoch: 12 [9600/17786 (54%)]\tLoss: 1.207335\n",
            "Train Epoch: 12 [10400/17786 (58%)]\tLoss: 0.844418\n",
            "Train Epoch: 12 [11200/17786 (63%)]\tLoss: 0.687796\n",
            "Train Epoch: 12 [12000/17786 (67%)]\tLoss: 1.494104\n",
            "Train Epoch: 12 [12800/17786 (72%)]\tLoss: 0.841628\n",
            "Train Epoch: 12 [13600/17786 (76%)]\tLoss: 0.903067\n",
            "Train Epoch: 12 [14400/17786 (81%)]\tLoss: 0.926805\n",
            "Train Epoch: 12 [15200/17786 (85%)]\tLoss: 0.693806\n",
            "Train Epoch: 12 [16000/17786 (90%)]\tLoss: 0.685442\n",
            "Train Epoch: 12 [16800/17786 (94%)]\tLoss: 0.270593\n",
            "Train Epoch: 12 [17600/17786 (99%)]\tLoss: 0.620404\n",
            "Train Epoch: 13 [0/17786 (0%)]\tLoss: 0.996762\n",
            "Train Epoch: 13 [800/17786 (4%)]\tLoss: 0.835318\n",
            "Train Epoch: 13 [1600/17786 (9%)]\tLoss: 0.354705\n",
            "Train Epoch: 13 [2400/17786 (13%)]\tLoss: 0.463766\n",
            "Train Epoch: 13 [3200/17786 (18%)]\tLoss: 0.454297\n",
            "Train Epoch: 13 [4000/17786 (22%)]\tLoss: 1.801252\n",
            "Train Epoch: 13 [4800/17786 (27%)]\tLoss: 0.176258\n",
            "Train Epoch: 13 [5600/17786 (31%)]\tLoss: 0.581269\n",
            "Train Epoch: 13 [6400/17786 (36%)]\tLoss: 1.492546\n",
            "Train Epoch: 13 [7200/17786 (40%)]\tLoss: 0.993574\n",
            "Train Epoch: 13 [8000/17786 (45%)]\tLoss: 0.682155\n",
            "Train Epoch: 13 [8800/17786 (49%)]\tLoss: 0.347633\n",
            "Train Epoch: 13 [9600/17786 (54%)]\tLoss: 1.012127\n",
            "Train Epoch: 13 [10400/17786 (58%)]\tLoss: 0.915932\n",
            "Train Epoch: 13 [11200/17786 (63%)]\tLoss: 0.466630\n",
            "Train Epoch: 13 [12000/17786 (67%)]\tLoss: 1.339196\n",
            "Train Epoch: 13 [12800/17786 (72%)]\tLoss: 0.348720\n",
            "Train Epoch: 13 [13600/17786 (76%)]\tLoss: 1.353325\n",
            "Train Epoch: 13 [14400/17786 (81%)]\tLoss: 0.515713\n",
            "Train Epoch: 13 [15200/17786 (85%)]\tLoss: 0.240269\n",
            "Train Epoch: 13 [16000/17786 (90%)]\tLoss: 0.855871\n",
            "Train Epoch: 13 [16800/17786 (94%)]\tLoss: 0.443679\n",
            "Train Epoch: 13 [17600/17786 (99%)]\tLoss: 0.687254\n",
            "Train Epoch: 14 [0/17786 (0%)]\tLoss: 0.731366\n",
            "Train Epoch: 14 [800/17786 (4%)]\tLoss: 1.524242\n",
            "Train Epoch: 14 [1600/17786 (9%)]\tLoss: 1.060947\n",
            "Train Epoch: 14 [2400/17786 (13%)]\tLoss: 0.546588\n",
            "Train Epoch: 14 [3200/17786 (18%)]\tLoss: 0.221738\n",
            "Train Epoch: 14 [4000/17786 (22%)]\tLoss: 1.066049\n",
            "Train Epoch: 14 [4800/17786 (27%)]\tLoss: 0.994076\n",
            "Train Epoch: 14 [5600/17786 (31%)]\tLoss: 0.603186\n",
            "Train Epoch: 14 [6400/17786 (36%)]\tLoss: 0.981010\n",
            "Train Epoch: 14 [7200/17786 (40%)]\tLoss: 0.428275\n",
            "Train Epoch: 14 [8000/17786 (45%)]\tLoss: 0.528249\n",
            "Train Epoch: 14 [8800/17786 (49%)]\tLoss: 0.532207\n",
            "Train Epoch: 14 [9600/17786 (54%)]\tLoss: 0.531056\n",
            "Train Epoch: 14 [10400/17786 (58%)]\tLoss: 0.274731\n",
            "Train Epoch: 14 [11200/17786 (63%)]\tLoss: 0.875221\n",
            "Train Epoch: 14 [12000/17786 (67%)]\tLoss: 0.426554\n",
            "Train Epoch: 14 [12800/17786 (72%)]\tLoss: 0.612929\n",
            "Train Epoch: 14 [13600/17786 (76%)]\tLoss: 0.640732\n",
            "Train Epoch: 14 [14400/17786 (81%)]\tLoss: 0.482010\n",
            "Train Epoch: 14 [15200/17786 (85%)]\tLoss: 0.599289\n",
            "Train Epoch: 14 [16000/17786 (90%)]\tLoss: 0.835162\n",
            "Train Epoch: 14 [16800/17786 (94%)]\tLoss: 0.670535\n",
            "Train Epoch: 14 [17600/17786 (99%)]\tLoss: 0.687000\n",
            "Train Epoch: 15 [0/17786 (0%)]\tLoss: 1.143820\n",
            "Train Epoch: 15 [800/17786 (4%)]\tLoss: 0.621917\n",
            "Train Epoch: 15 [1600/17786 (9%)]\tLoss: 2.733314\n",
            "Train Epoch: 15 [2400/17786 (13%)]\tLoss: 2.039691\n",
            "Train Epoch: 15 [3200/17786 (18%)]\tLoss: 0.343571\n",
            "Train Epoch: 15 [4000/17786 (22%)]\tLoss: 1.000559\n",
            "Train Epoch: 15 [4800/17786 (27%)]\tLoss: 0.806531\n",
            "Train Epoch: 15 [5600/17786 (31%)]\tLoss: 0.510566\n",
            "Train Epoch: 15 [6400/17786 (36%)]\tLoss: 1.378727\n",
            "Train Epoch: 15 [7200/17786 (40%)]\tLoss: 0.910674\n",
            "Train Epoch: 15 [8000/17786 (45%)]\tLoss: 0.546797\n",
            "Train Epoch: 15 [8800/17786 (49%)]\tLoss: 0.132075\n",
            "Train Epoch: 15 [9600/17786 (54%)]\tLoss: 0.417073\n",
            "Train Epoch: 15 [10400/17786 (58%)]\tLoss: 1.221884\n",
            "Train Epoch: 15 [11200/17786 (63%)]\tLoss: 0.211156\n",
            "Train Epoch: 15 [12000/17786 (67%)]\tLoss: 0.609814\n",
            "Train Epoch: 15 [12800/17786 (72%)]\tLoss: 0.755600\n",
            "Train Epoch: 15 [13600/17786 (76%)]\tLoss: 0.135614\n",
            "Train Epoch: 15 [14400/17786 (81%)]\tLoss: 0.455908\n",
            "Train Epoch: 15 [15200/17786 (85%)]\tLoss: 1.315404\n",
            "Train Epoch: 15 [16000/17786 (90%)]\tLoss: 1.485937\n",
            "Train Epoch: 15 [16800/17786 (94%)]\tLoss: 0.793298\n",
            "Train Epoch: 15 [17600/17786 (99%)]\tLoss: 0.530563\n",
            "Train Epoch: 16 [0/17786 (0%)]\tLoss: 1.135146\n",
            "Train Epoch: 16 [800/17786 (4%)]\tLoss: 0.408526\n",
            "Train Epoch: 16 [1600/17786 (9%)]\tLoss: 1.385801\n",
            "Train Epoch: 16 [2400/17786 (13%)]\tLoss: 1.066683\n",
            "Train Epoch: 16 [3200/17786 (18%)]\tLoss: 0.705989\n",
            "Train Epoch: 16 [4000/17786 (22%)]\tLoss: 0.114633\n",
            "Train Epoch: 16 [4800/17786 (27%)]\tLoss: 0.220460\n",
            "Train Epoch: 16 [5600/17786 (31%)]\tLoss: 0.524465\n",
            "Train Epoch: 16 [6400/17786 (36%)]\tLoss: 1.703250\n",
            "Train Epoch: 16 [7200/17786 (40%)]\tLoss: 0.197373\n",
            "Train Epoch: 16 [8000/17786 (45%)]\tLoss: 0.551276\n",
            "Train Epoch: 16 [8800/17786 (49%)]\tLoss: 0.707074\n",
            "Train Epoch: 16 [9600/17786 (54%)]\tLoss: 0.517977\n",
            "Train Epoch: 16 [10400/17786 (58%)]\tLoss: 0.221471\n",
            "Train Epoch: 16 [11200/17786 (63%)]\tLoss: 1.092254\n",
            "Train Epoch: 16 [12000/17786 (67%)]\tLoss: 1.147922\n",
            "Train Epoch: 16 [12800/17786 (72%)]\tLoss: 0.246700\n",
            "Train Epoch: 16 [13600/17786 (76%)]\tLoss: 1.315866\n",
            "Train Epoch: 16 [14400/17786 (81%)]\tLoss: 0.583059\n",
            "Train Epoch: 16 [15200/17786 (85%)]\tLoss: 0.361181\n",
            "Train Epoch: 16 [16000/17786 (90%)]\tLoss: 0.433054\n",
            "Train Epoch: 16 [16800/17786 (94%)]\tLoss: 0.290089\n",
            "Train Epoch: 16 [17600/17786 (99%)]\tLoss: 1.290048\n",
            "Train Epoch: 17 [0/17786 (0%)]\tLoss: 0.437815\n",
            "Train Epoch: 17 [800/17786 (4%)]\tLoss: 0.723081\n",
            "Train Epoch: 17 [1600/17786 (9%)]\tLoss: 1.042547\n",
            "Train Epoch: 17 [2400/17786 (13%)]\tLoss: 0.596844\n",
            "Train Epoch: 17 [3200/17786 (18%)]\tLoss: 0.799119\n",
            "Train Epoch: 17 [4000/17786 (22%)]\tLoss: 0.842963\n",
            "Train Epoch: 17 [4800/17786 (27%)]\tLoss: 0.270395\n",
            "Train Epoch: 17 [5600/17786 (31%)]\tLoss: 0.935497\n",
            "Train Epoch: 17 [6400/17786 (36%)]\tLoss: 0.182877\n",
            "Train Epoch: 17 [7200/17786 (40%)]\tLoss: 0.748940\n",
            "Train Epoch: 17 [8000/17786 (45%)]\tLoss: 0.928087\n",
            "Train Epoch: 17 [8800/17786 (49%)]\tLoss: 0.366646\n",
            "Train Epoch: 17 [9600/17786 (54%)]\tLoss: 1.773503\n",
            "Train Epoch: 17 [10400/17786 (58%)]\tLoss: 0.346769\n",
            "Train Epoch: 17 [11200/17786 (63%)]\tLoss: 0.451269\n",
            "Train Epoch: 17 [12000/17786 (67%)]\tLoss: 0.469399\n",
            "Train Epoch: 17 [12800/17786 (72%)]\tLoss: 0.663951\n",
            "Train Epoch: 17 [13600/17786 (76%)]\tLoss: 0.191356\n",
            "Train Epoch: 17 [14400/17786 (81%)]\tLoss: 0.360808\n",
            "Train Epoch: 17 [15200/17786 (85%)]\tLoss: 0.502509\n",
            "Train Epoch: 17 [16000/17786 (90%)]\tLoss: 1.820693\n",
            "Train Epoch: 17 [16800/17786 (94%)]\tLoss: 0.589770\n",
            "Train Epoch: 17 [17600/17786 (99%)]\tLoss: 0.349741\n",
            "Train Epoch: 18 [0/17786 (0%)]\tLoss: 2.063893\n",
            "Train Epoch: 18 [800/17786 (4%)]\tLoss: 0.419743\n",
            "Train Epoch: 18 [1600/17786 (9%)]\tLoss: 0.383445\n",
            "Train Epoch: 18 [2400/17786 (13%)]\tLoss: 0.662270\n",
            "Train Epoch: 18 [3200/17786 (18%)]\tLoss: 0.206394\n",
            "Train Epoch: 18 [4000/17786 (22%)]\tLoss: 0.246123\n",
            "Train Epoch: 18 [4800/17786 (27%)]\tLoss: 0.267295\n",
            "Train Epoch: 18 [5600/17786 (31%)]\tLoss: 0.585416\n",
            "Train Epoch: 18 [6400/17786 (36%)]\tLoss: 0.523161\n",
            "Train Epoch: 18 [7200/17786 (40%)]\tLoss: 0.409934\n",
            "Train Epoch: 18 [8000/17786 (45%)]\tLoss: 1.018868\n",
            "Train Epoch: 18 [8800/17786 (49%)]\tLoss: 0.631474\n",
            "Train Epoch: 18 [9600/17786 (54%)]\tLoss: 0.239592\n",
            "Train Epoch: 18 [10400/17786 (58%)]\tLoss: 0.548159\n",
            "Train Epoch: 18 [11200/17786 (63%)]\tLoss: 0.650609\n",
            "Train Epoch: 18 [12000/17786 (67%)]\tLoss: 0.516662\n",
            "Train Epoch: 18 [12800/17786 (72%)]\tLoss: 1.110799\n",
            "Train Epoch: 18 [13600/17786 (76%)]\tLoss: 0.237737\n",
            "Train Epoch: 18 [14400/17786 (81%)]\tLoss: 0.853691\n",
            "Train Epoch: 18 [15200/17786 (85%)]\tLoss: 1.098083\n",
            "Train Epoch: 18 [16000/17786 (90%)]\tLoss: 0.496735\n",
            "Train Epoch: 18 [16800/17786 (94%)]\tLoss: 0.463447\n",
            "Train Epoch: 18 [17600/17786 (99%)]\tLoss: 0.414123\n",
            "Train Epoch: 19 [0/17786 (0%)]\tLoss: 1.310086\n",
            "Train Epoch: 19 [800/17786 (4%)]\tLoss: 1.416358\n",
            "Train Epoch: 19 [1600/17786 (9%)]\tLoss: 0.925839\n",
            "Train Epoch: 19 [2400/17786 (13%)]\tLoss: 1.128652\n",
            "Train Epoch: 19 [3200/17786 (18%)]\tLoss: 0.480020\n",
            "Train Epoch: 19 [4000/17786 (22%)]\tLoss: 0.488281\n",
            "Train Epoch: 19 [4800/17786 (27%)]\tLoss: 0.509624\n",
            "Train Epoch: 19 [5600/17786 (31%)]\tLoss: 0.229308\n",
            "Train Epoch: 19 [6400/17786 (36%)]\tLoss: 1.605226\n",
            "Train Epoch: 19 [7200/17786 (40%)]\tLoss: 0.131404\n",
            "Train Epoch: 19 [8000/17786 (45%)]\tLoss: 0.223596\n",
            "Train Epoch: 19 [8800/17786 (49%)]\tLoss: 0.309664\n",
            "Train Epoch: 19 [9600/17786 (54%)]\tLoss: 0.189272\n",
            "Train Epoch: 19 [10400/17786 (58%)]\tLoss: 0.150316\n",
            "Train Epoch: 19 [11200/17786 (63%)]\tLoss: 0.359377\n",
            "Train Epoch: 19 [12000/17786 (67%)]\tLoss: 0.246809\n",
            "Train Epoch: 19 [12800/17786 (72%)]\tLoss: 0.176699\n",
            "Train Epoch: 19 [13600/17786 (76%)]\tLoss: 1.148759\n",
            "Train Epoch: 19 [14400/17786 (81%)]\tLoss: 1.083563\n",
            "Train Epoch: 19 [15200/17786 (85%)]\tLoss: 1.330845\n",
            "Train Epoch: 19 [16000/17786 (90%)]\tLoss: 0.675164\n",
            "Train Epoch: 19 [16800/17786 (94%)]\tLoss: 0.537185\n",
            "Train Epoch: 19 [17600/17786 (99%)]\tLoss: 1.936427\n",
            "Train Epoch: 20 [0/17786 (0%)]\tLoss: 0.623483\n",
            "Train Epoch: 20 [800/17786 (4%)]\tLoss: 0.675294\n",
            "Train Epoch: 20 [1600/17786 (9%)]\tLoss: 0.547240\n",
            "Train Epoch: 20 [2400/17786 (13%)]\tLoss: 0.256433\n",
            "Train Epoch: 20 [3200/17786 (18%)]\tLoss: 0.195685\n",
            "Train Epoch: 20 [4000/17786 (22%)]\tLoss: 0.167039\n",
            "Train Epoch: 20 [4800/17786 (27%)]\tLoss: 0.451980\n",
            "Train Epoch: 20 [5600/17786 (31%)]\tLoss: 0.333268\n",
            "Train Epoch: 20 [6400/17786 (36%)]\tLoss: 0.281494\n",
            "Train Epoch: 20 [7200/17786 (40%)]\tLoss: 0.156029\n",
            "Train Epoch: 20 [8000/17786 (45%)]\tLoss: 0.375736\n",
            "Train Epoch: 20 [8800/17786 (49%)]\tLoss: 0.053519\n",
            "Train Epoch: 20 [9600/17786 (54%)]\tLoss: 0.355856\n",
            "Train Epoch: 20 [10400/17786 (58%)]\tLoss: 0.177489\n",
            "Train Epoch: 20 [11200/17786 (63%)]\tLoss: 0.380624\n",
            "Train Epoch: 20 [12000/17786 (67%)]\tLoss: 0.684205\n",
            "Train Epoch: 20 [12800/17786 (72%)]\tLoss: 0.128575\n",
            "Train Epoch: 20 [13600/17786 (76%)]\tLoss: 0.019605\n",
            "Train Epoch: 20 [14400/17786 (81%)]\tLoss: 0.133483\n",
            "Train Epoch: 20 [15200/17786 (85%)]\tLoss: 0.362180\n",
            "Train Epoch: 20 [16000/17786 (90%)]\tLoss: 1.506316\n",
            "Train Epoch: 20 [16800/17786 (94%)]\tLoss: 0.446790\n",
            "Train Epoch: 20 [17600/17786 (99%)]\tLoss: 0.877646\n"
          ]
        }
      ],
      "source": [
        "def train(epoch, network):\n",
        "    network.train()\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data = Variable(data)\n",
        "\n",
        "        target = Variable(target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = network(data)\n",
        "        #print(output.size(), target.size())\n",
        "        error = nn.CrossEntropyLoss()\n",
        "\n",
        "        loss = error(output, target.type(torch.LongTensor))\n",
        "         \n",
        "        loss.backward()\n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        #loss = F.cross_entropy(output, target)\n",
        "        #loss.backward()\n",
        "        #optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "        \n",
        "network = Net3d()\n",
        "optimizer = optim.SGD(network.parameters(), lr=0.01)\n",
        "for epoch in range(1, 20 + 1):\n",
        "    train(epoch, network)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXgKOIH2CMR5"
      },
      "source": [
        "## Test Data\n",
        "Pick the predicted sign languages from top 1 to top 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "id": "DhvX_r20H8PY",
        "outputId": "70870777-316a-4b43-f0c1-1e71b5bc45c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 1:\n",
            "  Label Accuracy: 10/19 (0.5263157894736842%)\n",
            "  Total Accuracy: 123/476 (0.25840336134453784%)\n",
            "Top 2:\n",
            "  Label Accuracy: 10/19 (0.5263157894736842%)\n",
            "  Total Accuracy: 154/476 (0.3235294117647059%)\n",
            "Top 3:\n",
            "  Label Accuracy: 10/19 (0.5263157894736842%)\n",
            "  Total Accuracy: 171/476 (0.3592436974789916%)\n",
            "Top 4:\n",
            "  Label Accuracy: 11/19 (0.5789473684210527%)\n",
            "  Total Accuracy: 198/476 (0.41596638655462187%)\n",
            "Top 5:\n",
            "  Label Accuracy: 13/19 (0.6842105263157895%)\n",
            "  Total Accuracy: 222/476 (0.46638655462184875%)\n",
            "Top 6:\n",
            "  Label Accuracy: 14/19 (0.7368421052631579%)\n",
            "  Total Accuracy: 228/476 (0.4789915966386555%)\n",
            "Top 7:\n",
            "  Label Accuracy: 14/19 (0.7368421052631579%)\n",
            "  Total Accuracy: 237/476 (0.49789915966386555%)\n",
            "Top 8:\n",
            "  Label Accuracy: 14/19 (0.7368421052631579%)\n",
            "  Total Accuracy: 242/476 (0.5084033613445378%)\n",
            "Top 9:\n",
            "  Label Accuracy: 14/19 (0.7368421052631579%)\n",
            "  Total Accuracy: 249/476 (0.523109243697479%)\n",
            "Top 10:\n",
            "  Label Accuracy: 14/19 (0.7368421052631579%)\n",
            "  Total Accuracy: 280/476 (0.5882352941176471%)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def test(network):\n",
        "  xLabel = []\n",
        "  xTotal = []\n",
        "  for top in range(1, 10+1):\n",
        "    network.eval()\n",
        "    \n",
        "    test_loss = 0\n",
        "    correct = correctTotal = 0\n",
        "    allLabels = collections.defaultdict(list)\n",
        "    for data, target in test_loader:\n",
        "        #data, target = Variable(data, volatile=True), Variable(target)\n",
        "        output = network(data)\n",
        "\n",
        "        #test_loss += F.cross_entropy(output, target, reduction='sum').item() # sum up batch loss\n",
        "        #test_loss += F.cross_entropy(output, target, sum=True).item() # sum up batch loss\n",
        "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "\n",
        "        output = output.tolist()\n",
        "        target = target.tolist()\n",
        "        poss_top = [[i.index(j) for j in sorted(i, reverse=True)[:top]] for i in output]\n",
        "        #correctTotal += pred.eq(target.double().data.view_as(pred.double())).cpu().sum()\n",
        "\n",
        "        pred = pred.tolist()\n",
        "        for i in range(len(target)):\n",
        "          label = int(target[i])\n",
        "          if label in poss_top[i]:\n",
        "            correctTotal += 1\n",
        "          allLabels[label].extend(poss_top[i])\n",
        "\n",
        "    #test_loss /= len(train_loader.dataset)\n",
        "    \n",
        "    for label in allLabels:\n",
        "      most_common_labels = [i[0] for i in collections.Counter(allLabels[label]).most_common()]\n",
        "      #print(collections.Counter(allLabels[label]).most_common(), label)\n",
        "      #print(most_common_labels)\n",
        "      if label in most_common_labels:\n",
        "        correct += 1\n",
        "    print(f\"Top {top}:\")\n",
        "    print(f'  Label Accuracy: {correct}/{len(allLabels.keys())} ({correct / len(allLabels)}%)')\n",
        "    print(f'  Total Accuracy: {correctTotal}/{len(test_loader.dataset)} ({correctTotal / len(test_loader.dataset)}%)')\n",
        "    xLabel.append(correct / len(allLabels))\n",
        "    xTotal.append(correctTotal / len(test_loader.dataset))\n",
        "\n",
        "\n",
        "\n",
        "  plt.plot([i for i in range(1, 11)], xLabel, label='Accuracy per label')\n",
        "  plt.plot([i for i in range(1, 11)], xTotal, label='Accuracy per frame')\n",
        "  plt.xlabel(\"Top % Number Among Labels\", )\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  \n",
        "test(network)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "3dcnn_one_frame_per_sample",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
